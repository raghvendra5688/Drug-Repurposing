{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import dummy\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy\n",
    "\n",
    "from misc import save_model, load_model, regression_results, grid_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  ../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv\n",
      "Lengths --> X = 54175, Y = 54175\n",
      "Index(['LS_0', 'LS_1', 'LS_2', 'LS_3', 'LS_4', 'LS_5', 'LS_6', 'LS_7', 'LS_8',\n",
      "       'LS_9',\n",
      "       ...\n",
      "       'PLS_54', 'PLS_55', 'PLS_56', 'PLS_57', 'PLS_58', 'PLS_59', 'PLS_60',\n",
      "       'PLS_61', 'PLS_62', 'PLS_63'],\n",
      "      dtype='object', length=320)\n",
      "       LS_0      LS_1      LS_2      LS_3      LS_4      LS_5      LS_6  \\\n",
      "0  0.565035 -0.213065 -0.000764  0.015025 -0.031855 -0.012590 -0.000102   \n",
      "1  0.272218 -0.258328  0.000385  0.007196 -0.028770  0.062976 -0.000169   \n",
      "2  0.567573  0.057800  0.000016  0.012931 -0.012279  0.378251 -0.000176   \n",
      "3  0.801987  0.023184  0.000136  0.000772 -0.013787 -0.682254 -0.000193   \n",
      "4  0.833605 -0.166840  0.000225  0.007307 -0.028559 -0.172600 -0.000118   \n",
      "5  0.628016 -0.419587 -0.000024  0.001701 -0.006175 -0.149002 -0.000135   \n",
      "6  0.854284  0.167687  0.000309  0.019150 -0.011129  0.158235 -0.000310   \n",
      "7  0.898972 -0.057246  0.002465  0.004290 -0.010132  0.133053 -0.000133   \n",
      "8  0.445106  0.099132  0.000561  0.013880 -0.044212  0.032194 -0.000432   \n",
      "9  0.916135  0.124614  0.000845  0.014388 -0.029252  0.131530 -0.000099   \n",
      "\n",
      "       LS_7      LS_8      LS_9  ...     PLS_54    PLS_55    PLS_56  \\\n",
      "0  0.000173  0.043410 -0.000032  ...  -7.175925 -1.589016 -1.450142   \n",
      "1  0.000112 -0.048768 -0.000148  ...  16.786903  0.683173  7.260680   \n",
      "2  0.003412 -0.551354 -0.000105  ...  16.786903  0.683173  7.260680   \n",
      "3  0.002080 -0.425750 -0.000040  ...  16.786903  0.683173  7.260680   \n",
      "4  0.000324  0.208194 -0.000021  ...  16.786903  0.683173  7.260680   \n",
      "5  0.000187  0.086830 -0.000137  ...  16.256847  6.623242  6.126185   \n",
      "6  0.000683 -0.230810 -0.000049  ...  16.786903  0.683173  7.260680   \n",
      "7  0.000369  0.154465 -0.000041  ...  16.786903  0.683173  7.260680   \n",
      "8  0.001020 -0.259994 -0.000025  ...  16.786903  0.683173  7.260680   \n",
      "9  0.001031 -0.423787 -0.000053  ...  16.786903  0.683173  7.260680   \n",
      "\n",
      "       PLS_57     PLS_58    PLS_59     PLS_60     PLS_61    PLS_62    PLS_63  \n",
      "0  -97.836319 -12.442183  8.642500  14.662628  -5.112053 -4.386289  1.195183  \n",
      "1 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "2 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "3 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "4 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "5 -140.331253  -2.526256 -9.824449  -7.932061 -11.736423 -8.355380 -9.171484  \n",
      "6 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "7 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "8 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "9 -132.681641   9.667920 -0.224070  -0.795782  10.744227 -5.754991  7.939027  \n",
      "\n",
      "[10 rows x 320 columns]\n",
      "(54175, 320) (54175,)\n",
      "Index(['LS_0', 'LS_1', 'LS_2', 'LS_3', 'LS_4', 'LS_5', 'LS_6', 'LS_7', 'LS_8',\n",
      "       'LS_9',\n",
      "       ...\n",
      "       'PLS_54', 'PLS_55', 'PLS_56', 'PLS_57', 'PLS_58', 'PLS_59', 'PLS_60',\n",
      "       'PLS_61', 'PLS_62', 'PLS_63'],\n",
      "      dtype='object', length=320)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Options of settings with different Xs and Ys \n",
    "options = [\"../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv\",\n",
    "           \"../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_MFP_LS.csv\",\n",
    "           \"..\"] #(to be continued)\n",
    "\n",
    "data_type_options = [\"LS_Compound_LS_Protein\",\n",
    "                     \"MFP_Compound_LS_Protein\",\n",
    "                     \"..\"\n",
    "                    ]\n",
    "\n",
    "# input option is also used to control the model parameters below\n",
    "input_option = 0\n",
    "\n",
    "classification_task = False\n",
    "classification_th = 85\n",
    "\n",
    "data_type=data_type_options[input_option]\n",
    "filename = options[input_option]\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    print(\"Loading \", filename)\n",
    "    big_df = pd.read_csv(filename, header='infer', delimiter=\",\")\n",
    "    total_length = len(big_df.columns)\n",
    "    X = big_df.iloc[:,range(5,total_length)]\n",
    "    Y = big_df[['pchembl_value']].to_numpy().flatten()\n",
    "    meta_X = big_df.iloc[:,[0,1,2,3]]\n",
    "    print(\"Lengths --> X = %d, Y = %d\" % (len(X), len(Y)))\n",
    "\n",
    "print(X.columns)\n",
    "n_samples = len(X)\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "X_train = X\n",
    "y_train = Y\n",
    "print(X_train[:10])\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_train.columns)\n",
    "print(big_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(labels, predictions):\n",
    "    \n",
    "    predictions = predictions.round()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, predictions)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    aupr = metrics.average_precision_score(labels,predictions)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predictions),\\\n",
    "            metrics.f1_score(labels, predictions, average='binary'),\\\n",
    "            auc,\\\n",
    "            aupr\n",
    "\n",
    "\n",
    "def calculate_regression_metrics(labels, predictions):\n",
    "    return metrics.mean_absolute_error(labels, predictions),\\\n",
    "            metrics.mean_squared_error(labels, predictions),\\\n",
    "            metrics.r2_score(labels, predictions),\\\n",
    "            scipy.stats.pearsonr(np.array(labels).flatten(),np.array(predictions.flatten()))[0],\\\n",
    "            scipy.stats.spearmanr(np.array(labels).flatten(),np.array(predictions.flatten()))[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning_steps(method,scoring,data_type,task,model,params,X_train,y_train,n_iter):\n",
    "    \n",
    "    gs = grid_search_cv(model, params, X_train, y_train, scoring=scoring, n_iter = n_iter)\n",
    "\n",
    "    y_pred = gs.predict(X_train)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "\n",
    "    if task:\n",
    "        results=calculate_classification_metrics(y_train, y_pred)\n",
    "        print(\"Acc: %.3f, F1: %.3f, AUC: %.3f, AUPR: %.3f\" % (results[0], results[1], results[2], results[3]))\n",
    "    else:\n",
    "        results=calculate_regression_metrics(y_train,y_pred)\n",
    "        print(\"MAE: %.3f, MSE: %.3f, R2: %.3f, Pearson R: %.3f, Spearman R: %.3f\" % (results[0], results[1], results[2], results[3], results[4]))\n",
    "   \n",
    "    print('Parameters')\n",
    "    print('----------')\n",
    "    for p,v in gs.best_estimator_.get_params().items():\n",
    "        print(p, \":\", v)\n",
    "    print('-' * 80)\n",
    "\n",
    "    if task:\n",
    "        save_model(gs, \"%s_models/%s_%s_classifier_gs.pk\" % (method,method,data_type))\n",
    "        save_model(gs.best_estimator_, \"%s_models/%s_%s_classifier_best_estimator.pk\" %(method,method,data_type))\n",
    "    else:\n",
    "        save_model(gs, \"%s_models/%s_%s_regressor_gs.pk\" % (method,method,data_type))\n",
    "        save_model(gs.best_estimator_, \"%s_models/%s_%s_regressor_best_estimator.pk\" %(method,method,data_type))\n",
    "        \n",
    "    return(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification_task:\n",
    "    model = ensemble.RandomForestRegressor(n_estimators=100, criterion='auc',\n",
    "                                            max_depth=None, min_samples_split=2,\n",
    "                                            min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                            max_features='auto', max_leaf_nodes=None,\n",
    "                                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                            bootstrap=True, oob_score=False,\n",
    "                                            n_jobs=-1, random_state=328, verbose=1,\n",
    "                                            warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "else:\n",
    "    model = ensemble.RandomForestRegressor(n_estimators=100, criterion='mse',\n",
    "                                            max_depth=None, min_samples_split=2,\n",
    "                                            min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                            max_features='auto', max_leaf_nodes=None,\n",
    "                                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                            bootstrap=True, oob_score=False,\n",
    "                                            n_jobs=-1, random_state=328, verbose=1,\n",
    "                                            warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "\n",
    "# Grid parameters\n",
    "param_rf = {\"n_estimators\": scipy.stats.randint(20, 500),\n",
    "               \"max_depth\": scipy.stats.randint(1, 9),\n",
    "               \"min_samples_leaf\": scipy.stats.randint(1, 10),\n",
    "               \"max_features\": scipy.stats.uniform.ppf([0.1,0.7])\n",
    "}\n",
    "\n",
    "n_iter=200\n",
    "\n",
    "if classification_task:\n",
    "    rf_gs=supervised_learning_steps(\"rf\",\"roc_auc\",data_type,classification_task,model,param_rf,X_train,y_train,n_iter)\n",
    "else:\n",
    "    rf_gs=supervised_learning_steps(\"rf\",\"r2\",data_type,classification_task,model,param_rf,X_train,y_train,n_iter)\n",
    "\n",
    "rf_gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs = load_model(\"rf_models/rf__LS_Drug_LS_Protein_regressor_gs.pk\")\n",
    "np.max(rf_gs.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "file_list = [\"../data/Test_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv\",\n",
    "             \"../data/Test_Compound_Viral_interactions_for_Supervised_Learning_with_MFP_LS.csv\"]\n",
    "\n",
    "filename = file_list[input_option]\n",
    "with open(filename, \"rb\") as file:\n",
    "    print(\"Loading \", filename)\n",
    "    big_df = pd.read_csv(filename, header='infer', delimiter=\",\")\n",
    "    total_length = len(big_df.columns)\n",
    "    X = big_df.iloc[:,range(5,total_length)]\n",
    "    Y = big_df[['pchembl_value']].to_numpy().flatten()\n",
    "    meta_X = big_df.iloc[:,[0,1,2,3]]\n",
    "    print(\"Lengths --> X = %d, Y = %d\" % (len(X), len(Y)))\n",
    "\n",
    "print(X.columns)\n",
    "n_samples = len(X)\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "X_test = X\n",
    "y_test = Y\n",
    "rf_best = rf_gs.best_estimator_\n",
    "y_pred_rf=rf_best.predict(X_test)\n",
    "print(calculate_regression_metrics(y_test,y_pred_rf))\n",
    "\n",
    "#Write the output in the results folder\n",
    "meta_X[\"predictions\"]=y_pred_xgb\n",
    "meta_X[\"labels\"]=y_test\n",
    "rev_output_df = meta_X.iloc[:,[0,2,4,5]].copy()\n",
    "rev_output_df.to_csv(\"../results/RF_\"+data_type_options[input_option]+\"supervised_test_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## load JS visualization code to notebook (Doesn't work for random forest)\n",
    "#shap.initjs()\n",
    "\n",
    "## explain the model's predictions using SHAP values\n",
    "#explainer = shap.TreeExplainer(xgb_gs.best_estimator_)\n",
    "#shap_values = explainer.shap_values(X_train)\n",
    "#shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get results for SARS-COV-2\n",
    "#big_X_test = pd.read_csv(\"../data/COVID-19/sars_cov_2_additional_compound_viral_interactions_to_predict_with_LS_v2.csv\",header='infer',sep=\",\")\n",
    "#total_length = len(big_X_test.columns)\n",
    "#X_test = big_X_test.iloc[:,range(8,total_length)]\n",
    "#rf_best = load_model(\"../models/rf_models/rf__LS_Drug_LS_Protein_regressor_best_estimator.pk\")\n",
    "#y_pred = rf_best.predict(X_test)\n",
    "\n",
    "#meta_X_test = big_X_test.iloc[:,[0,2]].copy()\n",
    "#meta_X_test.loc[:,'predictions']=y_pred\n",
    "#meta_X_test.loc[:,'labels']=0\n",
    "#meta_X_test.to_csv(\"../results/RF_supervised_sars_cov2_additional_test_predictions.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
