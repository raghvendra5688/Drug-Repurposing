{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import dummy\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy\n",
    "\n",
    "from misc import save_model, load_model, regression_results, grid_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7336c6a86273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_option\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mbig_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv'"
     ]
    }
   ],
   "source": [
    "# Options of settings with different Xs and Ys \n",
    "options = [\"../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv\",\n",
    "           \"../data/Train_Compound_Viral_interactions_for_Supervised_Learning_with_MFP_LS.csv\",\n",
    "           \"..\"] #(to be continued)\n",
    "\n",
    "data_type_options = [\"LS_Compound_LS_Protein\",\n",
    "                     \"MFP_Compound_LS_Protein\",\n",
    "                     \"..\"\n",
    "                    ]\n",
    "\n",
    "# input option is also used to control the model parameters below\n",
    "input_option = 0\n",
    "\n",
    "classification_task = False\n",
    "classification_th = 85\n",
    "\n",
    "data_type=data_type_options[input_option]\n",
    "filename = options[input_option]\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    print(\"Loading \", filename)\n",
    "    big_df = pd.read_csv(filename, header='infer', delimiter=\",\")\n",
    "    total_length = len(big_df.columns)\n",
    "    X = big_df.iloc[:,range(5,total_length)]\n",
    "    Y = big_df[['pchembl_value']].to_numpy().flatten()\n",
    "    meta_X = big_df.iloc[:,[0,1,2,3]]\n",
    "    print(\"Lengths --> X = %d, Y = %d\" % (len(X), len(Y)))\n",
    "\n",
    "print(X.columns)\n",
    "n_samples = len(X)\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "X_train = X\n",
    "y_train = Y\n",
    "print(X_train[:10])\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_train.columns)\n",
    "print(big_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(labels, predictions):\n",
    "    \n",
    "    predictions = predictions.round()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, predictions)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    aupr = metrics.average_precision_score(labels,predictions)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predictions),\\\n",
    "            metrics.f1_score(labels, predictions, average='binary'),\\\n",
    "            auc,\\\n",
    "            aupr\n",
    "\n",
    "\n",
    "def calculate_regression_metrics(labels, predictions):\n",
    "    return metrics.mean_absolute_error(labels, predictions),\\\n",
    "            metrics.mean_squared_error(labels, predictions),\\\n",
    "            metrics.r2_score(labels, predictions),\\\n",
    "            scipy.stats.pearsonr(np.array(labels).flatten(),np.array(predictions.flatten()))[0],\\\n",
    "            scipy.stats.spearmanr(np.array(labels).flatten(),np.array(predictions.flatten()))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning_steps(method,scoring,data_type,task,model,params,X_train,y_train,n_iter):\n",
    "    \n",
    "    gs = grid_search_cv(model, params, X_train, y_train, scoring=scoring, n_iter = n_iter)\n",
    "\n",
    "    y_pred = gs.predict(X_train)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "\n",
    "    if task:\n",
    "        results=calculate_classification_metrics(y_train, y_pred)\n",
    "        print(\"Acc: %.3f, F1: %.3f, AUC: %.3f, AUPR: %.3f\" % (results[0], results[1], results[2], results[3]))\n",
    "    else:\n",
    "        results=calculate_regression_metrics(y_train,y_pred)\n",
    "        print(\"MAE: %.3f, MSE: %.3f, R2: %.3f, Pearson R: %.3f, Spearman R: %.3f\" % (results[0], results[1], results[2], results[3], results[4]))\n",
    "   \n",
    "    print('Parameters')\n",
    "    print('----------')\n",
    "    for p,v in gs.best_estimator_.get_params().items():\n",
    "        print(p, \":\", v)\n",
    "    print('-' * 80)\n",
    "\n",
    "    if task:\n",
    "        save_model(gs, \"%s_models/%s_%s_classifier_gs.pk\" % (method,method,data_type))\n",
    "        save_model(gs.best_estimator_, \"%s_models/%s_%s_classifier_best_estimator.pk\" %(method,method,data_type))\n",
    "    else:\n",
    "        save_model(gs, \"%s_models/%s_%s_regressor_gs.pk\" % (method,method,data_type))\n",
    "        save_model(gs.best_estimator_, \"%s_models/%s_%s_regressor_best_estimator.pk\" %(method,method,data_type))\n",
    "        \n",
    "    return(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Build the Generalized Linear Regression model\n",
    "if classification_task:\n",
    "    model = linear_model.LogisticRegression()\n",
    "else:\n",
    "    model = linear_model.LinearRegression()\n",
    "\n",
    "# Grid parameters\n",
    "if classification_task:\n",
    "    params_lr = [\n",
    "       {\n",
    "            'C': scipy.stats.randint(20, 500),\n",
    "            'fit_intercept': [True, False],\n",
    "       }\n",
    "    ]\n",
    "else:\n",
    "    params_lr = [\n",
    "       {\n",
    "            'normalize': [True, False],\n",
    "            'fit_intercept': [True, False],\n",
    "       }\n",
    "    ]\n",
    "\n",
    "n_iter = 1500\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_copy = scaler.fit_transform(X_train)\n",
    "\n",
    "if classification_task:\n",
    "    lr_gs=supervised_learning_steps(\"glm\",\"roc_auc\",data_type,classification_task,model,params_lr,X_train_copy,y_train,n_iter)\n",
    "else:\n",
    "    lr_gs=supervised_learning_steps(\"glm\",\"r2\",data_type,classification_task,model,params_lr,X_train_copy,y_train,n_iter)\n",
    "    \n",
    "print(lr_gs.cv_results_)\n",
    "save_model(scaler, \"%s_models/%s_%s_scaling_gs.pk\" % (\"glm\",\"glm\",data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the generalized linear regression model on separate test set\n",
    "np.max(lr_gs.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "file_list = [\"../data/Test_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv\",\n",
    "             \"../data/Test_Compound_Viral_interactions_for_Supervised_Learning_with_MFP_LS.csv\"]\n",
    "\n",
    "filename = file_list[input_option]\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    print(\"Loading \", filename)\n",
    "    big_df = pd.read_csv(filename, header='infer', delimiter=\",\")\n",
    "    total_length = len(big_df.columns)\n",
    "    X = big_df.iloc[:,range(5,total_length)]\n",
    "    Y = big_df[['pchembl_value']].to_numpy().flatten()\n",
    "    meta_X = big_df.iloc[:,[0,1,2,3]]\n",
    "    print(\"Lengths --> X = %d, Y = %d\" % (len(X), len(Y)))\n",
    "\n",
    "print(X.columns)\n",
    "n_samples = len(X)\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "X_test = X\n",
    "y_test = Y\n",
    "lr_best = lr_gs.best_estimator_\n",
    "y_pred_lr=lr_best.predict(scaler.transform(X_test))\n",
    "print(calculate_regression_metrics(y_test,y_pred_lr))\n",
    "\n",
    "#Write the prediction of GLM model\n",
    "meta_X[\"predictions\"]=y_pred_lr\n",
    "meta_X[\"labels\"]=y_test\n",
    "rev_output_df = meta_X.iloc[:,[0,2,4,5]].copy()\n",
    "rev_output_df.to_csv(\"../results/GLM_\"+data_type_options[input_option]+\"_supervised_test_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-63aa70a82bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDummyRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_regression_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Dummy mean regressor and median regressor\n",
    "strategy = 'mean'\n",
    "model = dummy.DummyRegressor(strategy=strategy)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_mean = model.predict(X_test)\n",
    "print(calculate_regression_metrics(y_test,y_pred_mean))\n",
    "\n",
    "strategy = 'median'\n",
    "model = dummy.DummyRegressor(strategy=strategy)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_median = model.predict(X_test)\n",
    "print(calculate_regression_metrics(y_test,y_pred_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get results for SARS-COV-2 for SMILES embeddig + protein embedding (input option = 0) or Morgan fingerprints + protein emedding  (input_option = 1)\n",
    "input_option=0\n",
    "if (input_option==0):\n",
    "    big_X_test = pd.read_csv(\"../data/sars_cov_2_Compound_Viral_interactions_for_Supervised_Learning_with_LS_LS.csv\",header='infer',sep=\",\")\n",
    "    total_length = len(big_X_test.columns)\n",
    "    X_test = big_X_test.iloc[:,range(5,total_length)]\n",
    "    lr_best = load_model(\"../models/glm_models/glm_LS_Compound_LS_Protein_regressor_best_estimator.pk\")\n",
    "    scaler = load_model(\"../models/glm_models/glm_LS_Compound_LS_Protein_scaling_gs.pk\")\n",
    "    y_pred = lr_best.predict(scaler.transform(X_test))\n",
    "\n",
    "    meta_X_test = big_X_test.iloc[:,[0,2]].copy()\n",
    "    meta_X_test.loc[:,'predictions']=y_pred\n",
    "    meta_X_test.loc[:,'labels']=0\n",
    "    meta_X_test.to_csv(\"../results/GLM_\"+data_type_options[input_option]+\"supervised_sars_cov_2_predictions.csv\",index=False)\n",
    "elif (input_option==1):\n",
    "    big_X_test = pd.read_csv(\"../data/sars_cov_2_Compound_Viral_interactions_for_Supervised_Learning_with_MFP_LS.csv\",header='infer',sep=\",\")\n",
    "    total_length = len(big_X_test.columns)\n",
    "    X_test = big_X_test.iloc[:,range(5,total_length)]\n",
    "    lr_best = load_model(\"../models/glm_models/glm_MFP_Compound_LS_Protein_regressor_best_estimator.pk\")\n",
    "    scaler = load_model(\"../models/glm_models/glm_MFP_Compound_LS_Protein_scaling_gs.pk\")\n",
    "    y_pred = lr_best.predict(scaler.transform(X_test))\n",
    "\n",
    "    meta_X_test = big_X_test.iloc[:,[0,2]].copy()\n",
    "    meta_X_test.loc[:,'predictions']=y_pred\n",
    "    meta_X_test.loc[:,'labels']=0\n",
    "    meta_X_test.to_csv(\"../results/GLM_\"+data_type_options[input_option]+\"supervised_sars_cov_2_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
